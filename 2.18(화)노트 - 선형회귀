2.18(화)노트 - 선형회귀

- 딥러닝은 선형회귀의 집합이라 할수 있다
- 선형회귀는 이후에 관련된 모델들이 많다 vs SVM, RF 는 단일


[선형회귀 모델의 예측함수] Linear Regression

y = w[0]∗x[0] + b  (특성1개)

y = w[0]∗x[0] + w[1]∗x[1] + ...+ w[p]∗x[p] + b  (특성여러개)


- 모델 파라미터 : w 와 b - 학습되어 변경됨
- 하이퍼 파라미터(Hyper Parameter) : 직접 설정해 줘야 하는 파라미터를 

* w(weight) = 가중치, 힘, 기울기 : 입력데이터에 힘을 조절하는 역할
 - 머신러닝 모델이 직접구함
 - w가 높아지면 복잡도 ↑ > 민감도 ↑ > 과대적합 가능성 ↑
 
* p는 특성의 계수 : csv파일의 컬럼의 개수 / 이미지파일의 픽셀 개수
 
 
y = w[0]∗x[0] + b




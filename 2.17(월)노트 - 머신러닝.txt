2.17(월)노트 - 머신러닝

[머신러닝 개요]

1.지도학습
2.비지도학습 : 개발자가 답을 내려줘야 함

3.강화학습
  ex)알파고
 - 알파제로 : 더 뛰어나다


[딥러닝]

<구글드라이브 자료 설명> http://bit.ly/2SAjGgt

02_통계데이터분석
 : 머신러닝 배우기 전 통계기초

03_HTML
 : 크롤링을 위해 > 몽고DB,하둡에 저장

05_머신러닝
 : main 임

07_몽고디비
 : 간단하게만

08_딥러닝
 : 

* 수학을 하는 이유?
 : 과정을 배우기 위한 > 상대적으로 쉽다


[00. 지도학습 시작하기]

<순서>
1. 데이터로 스키마를 만들기
2. 가설 세우기
3. scatter 찍어보는 등 시각화로 가늠하기 : 특성공학(svm등) 쓰기
4. 섞고 자르기
5. train data 훈련
6. 예측, 테스트
7. 평가

iris 붓꽃데이터

항상 통계적으로 시각화를 해보다보면 머신러닝적인게 나온다

scatter를 찍어보면 대충 윤곽이 보임
  - 시각화해서 어느정도 필터링을 해봐야함

통계학이 쓰임


fit을 4개 했으면 predict도 4개를 해야함
 > 배열.shake 하면 행,열 개수가 나오므로 개수를 확인하기


데이터 클래스를 100% 다 정렬시키면 안되는 이유?
 - 검증을 위한 여분의 데이터가 필요하다
 - 일부는 훈련용 / 테스트용으로 배정해야함
 - 일반적인 비율 > 75:25
 - 중간에 셔플링(랜덤하게) 하는 과정이 필요함
 - 섞어서 자르기 : 프레이 > 테스트 > 스플릿


from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(iris_dataset['data'], iris_dataset['target'], random_state = 0) 
# x, y는 지정값
#랜덤은 고정




[00. 지도학습의 종류]

분류 기본은 이진분류


<회귀 Regression>
쉽게 얘기하면 "연속적인 숫자" > 실수형태로 표현됨
정수:Classification
실수:Regression



<일반화(generalization)> 머신러닝에서 가장 어려운 부분


과대적합 : 규칙이 너무 많고 복잡해지기 때문에 민감해져 일반화가 어렵습니다.
과소적합 : 규칙이 적용되는 범위가 너무 넓어 모델의 신뢰도가 떨어집니다.













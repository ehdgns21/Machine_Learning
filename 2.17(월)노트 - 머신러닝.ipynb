{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.17(월)노트 - 머신러닝\n",
    "\n",
    "[머신러닝 개요]\n",
    "\n",
    "1.지도학습\n",
    "2.비지도학습 : 개발자가 답을 내려줘야 함\n",
    "\n",
    "3.강화학습\n",
    "  ex)알파고\n",
    " - 알파제로 : 더 뛰어나다\n",
    "\n",
    "\n",
    "[딥러닝]\n",
    "\n",
    "<구글드라이브 자료 설명> http://bit.ly/2SAjGgt\n",
    "\n",
    "02_통계데이터분석\n",
    " : 머신러닝 배우기 전 통계기초\n",
    "\n",
    "03_HTML\n",
    " : 크롤링을 위해 > 몽고DB,하둡에 저장\n",
    "\n",
    "05_머신러닝\n",
    " : main 임\n",
    "\n",
    "07_몽고디비\n",
    " : 간단하게만\n",
    "\n",
    "08_딥러닝\n",
    " : \n",
    "\n",
    "* 수학을 하는 이유?\n",
    " : 과정을 배우기 위한 > 상대적으로 쉽다\n",
    "\n",
    "\n",
    "[00. 지도학습 시작하기]\n",
    "\n",
    "<순서>\n",
    "1. 데이터로 스키마를 만들기\n",
    "2. 가설 세우기\n",
    "3. scatter 찍어보는 등 시각화로 가늠하기 : 특성공학(svm등) 쓰기\n",
    "4. 섞고 자르기\n",
    "5. train data 훈련\n",
    "6. 예측, 테스트\n",
    "7. 평가\n",
    "\n",
    "iris 붓꽃데이터\n",
    "\n",
    "항상 통계적으로 시각화를 해보다보면 머신러닝적인게 나온다\n",
    "\n",
    "scatter를 찍어보면 대충 윤곽이 보임\n",
    "  - 시각화해서 어느정도 필터링을 해봐야함\n",
    "\n",
    "통계학이 쓰임\n",
    "\n",
    "\n",
    "fit을 4개 했으면 predict도 4개를 해야함\n",
    " > 배열.shake 하면 행,열 개수가 나오므로 개수를 확인하기\n",
    "\n",
    "\n",
    "데이터 클래스를 100% 다 정렬시키면 안되는 이유?\n",
    " - 검증을 위한 여분의 데이터가 필요하다\n",
    " - 일부는 훈련용 / 테스트용으로 배정해야함\n",
    " - 일반적인 비율 > 75:25\n",
    " - 중간에 셔플링(랜덤하게) 하는 과정이 필요함\n",
    " - 섞어서 자르기 : 프레이 > 테스트 > 스플릿\n",
    "\n",
    "- train_test_split : 섞고 잘라서 훈련용, 테스트용 데이터셋을 생성\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_dataset['data'], iris_dataset['target'], random_state = 0) \n",
    "- x, y는 지정값\n",
    "-랜덤은 고정\n",
    "\n",
    "\n",
    "\n",
    "[00. 지도학습의 종류]\n",
    "\n",
    "분류 기본은 이진분류\n",
    "\n",
    "\n",
    "<회귀 Regression>\n",
    "쉽게 얘기하면 \"연속적인 숫자\" > 실수형태로 표현됨\n",
    "정수:Classification\n",
    "실수:Regression\n",
    "\n",
    "\n",
    "\n",
    "<일반화(generalization)> 머신러닝에서 가장 어려운 부분\n",
    "\n",
    "\n",
    "과대적합 : 규칙이 너무 많고 복잡해지기 때문에 민감해져 일반화가 어렵습니다.\n",
    "과소적합 : 규칙이 적용되는 범위가 너무 넓어 모델의 신뢰도가 떨어집니다.\n",
    "\n",
    "\n",
    " cf. 거리 2종류\n",
    "1) 맨하탄 거리\n",
    "2) 유클라디언 거리\n",
    "\n",
    "\n",
    "<k-nn 분류 모델>\n",
    " - 이웃의 개수가 많을수록 복잡\n",
    "\n",
    "- k-NN 모델 만들기\n",
    "- fit : (X_train, y_train) -> 훈련\n",
    "- predict : ( x ) -> 예측하기\n",
    "- score : (X, y) -> 점수 (predict의 평균)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* 정확도 보는 차이점(이유: 오차역전파때문)\n",
    "머신러닝 : score로 정확도를 가늠\n",
    "딥러닝 : loss 값으로 정확도를 가늠\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
